# -*- coding: utf-8 -*-
import json
from pathlib import Path
from typing import Any, Dict, List, Optional

import pandas as pd
import numpy as np
import requests

from playwright.sync_api import sync_playwright

# ===== å…¬å¸ / å¹´ä»½è¨­å®š =====
COMPANIES = {
    "2330": "å°ç©é›»", "2317": "é´»æµ·", "2454": "è¯ç™¼ç§‘", "2881": "å¯Œé‚¦é‡‘",
    "2412": "ä¸­è¯é›»", "2382": "å»£é”", "2308": "å°é”é›»", "2882": "åœ‹æ³°é‡‘",
    "2891": "ä¸­ä¿¡é‡‘", "3711": "æ—¥æœˆå…‰æŠ•æ§",
}
YEARS_HTML = [2022, 2021]

OUTDIR = Path("./esg_scraper_all_2022_2021")
OUTDIR.mkdir(parents=True, exist_ok=True)
RAW_DIR = OUTDIR / "raw"
RAW_DIR.mkdir(exist_ok=True)

CSV_PATH = OUTDIR / "all_companies_long.csv"
JSON_PATH = OUTDIR / "all_companies_wide.json"

# ===== é¡åˆ¥å°æ‡‰ =====
ENV_TOPICS = {"æº«å®¤æ°£é«”æ’æ”¾","æ°£å€™ç›¸é—œè­°é¡Œç®¡ç†","èƒ½æºç®¡ç†","æ°´è³‡æºç®¡ç†","å»¢æ£„ç‰©ç®¡ç†","ç”¢å“ç”Ÿå‘½é€±æœŸ"}
SOC_TOPICS = {"äººåŠ›ç™¼å±•","è·æ¥­å®‰å…¨è¡›ç”Ÿ","ç”¢å“å“è³ªèˆ‡å®‰å…¨"}
GOV_TOPICS = {"è‘£äº‹æœƒ","åŠŸèƒ½æ€§å§”å“¡æœƒ","æŒè‚¡åŠæ§åˆ¶åŠ›","æŠ•è³‡äººæºé€š","é¢¨éšªç®¡ç†æ”¿ç­–","åç«¶çˆ­è¡Œç‚ºæ³•å¾‹è¨´è¨Ÿ"}
def topic_to_category(t): 
    if t in ENV_TOPICS: return "ç’°å¢ƒ"
    if t in SOC_TOPICS: return "ç¤¾æœƒ"
    if t in GOV_TOPICS: return "æ²»ç†"
    return "â€”"

# ===== æ•¸å€¼æ¸…ç† =====
def to_value(x):
    if not x:return None
    s = str(x).strip().replace(",", "")
    if s.endswith("%"):
        try:return float(s[:-1]) / 100
        except:return s
    try:return float(s)
    except:return s


# ===== HTML ç‰ˆï¼ˆfor 2021 2022ï¼‰ =====
def fetch_html_table(code: str, name: str, year: int) -> pd.DataFrame:
    url = f"https://esggenplus.twse.com.tw/inquiry/info/individual?companyCode={code}&year={year}"
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        ctx = browser.new_context()
        page = ctx.new_page()
        page.goto(url, wait_until="networkidle", timeout=60000)

        js = r"""
        () => {
          const trs = document.querySelectorAll('table[aria-label="æŸ¥è©¢çµæœ"] tbody tr[id], table[aria-label="æŸ¥è©¢çµæœ"] tbody tr[data-tr-key]');
          const out = [];
          trs.forEach(tr => {
            const rawKey = tr.getAttribute("id") || tr.getAttribute("data-tr-key") || "";
            const indicator = rawKey.split("_").pop()?.trim() || "";
            const tds = Array.from(tr.querySelectorAll("td"));
            let field = "";
            let value = "";

            const w150 = tr.querySelector("td.w150-p");
            if (w150) {
              field = w150.innerText.trim();
              const idx = tds.indexOf(w150);
              if (idx >= 0 && idx + 1 < tds.length)
                value = (tds[idx + 1].innerText || "").trim();
            } else {
              if (tds.length >= 1) field = (tds[0].innerText || "").trim();
              const desc = tr.querySelector("td.desc-col");
              if (desc) value = desc.innerText.trim();
              else if (tds.length >= 2) value = (tds[1].innerText || "").trim();
            }
            if (indicator && field) out.push({indicator, field, value});
          });
          return out;
        }
        """
        rows = page.evaluate(js)
        browser.close()

    data = []
    for r in rows:
        cat = topic_to_category(r["indicator"])
        val = to_value(r["value"])
        data.append({
            "å…¬å¸ä»£ç¢¼": code, "å…¬å¸åç¨±": name, "å¹´åº¦": year,
            "é¡åˆ¥": cat, "æŒ‡æ¨™åç¨±": r["indicator"], "æ¬„ä½åç¨±": r["field"], "æ•¸å€¼": val
        })
    return pd.DataFrame(data)

# ===== ä¸»æµç¨‹ =====
def main():
    all_dfs = []
    for code, name in COMPANIES.items():
        
        # --- å† HTML å¹´ä»½ ---
        for y in YEARS_HTML:
            try:
                df = fetch_html_table(code, name, y)
                if not df.empty:
                    all_dfs.append(df)
                    print(f"âœ” {name}({code}) {y} HTML æŠ“å– {len(df)} ç­†")
            except Exception as e:
                print(f"âœ— {name}({code}) {y} HTML å¤±æ•—: {e}")

    if not all_dfs:
        print("âœ— æ²’æœ‰ä»»ä½•è³‡æ–™"); return
    merged = pd.concat(all_dfs, ignore_index=True)
    merged.to_csv(CSV_PATH, index=False, encoding="utf-8-sig")

    merged["path"] = merged[["é¡åˆ¥","æŒ‡æ¨™åç¨±","æ¬„ä½åç¨±"]].astype(str).agg("/".join, axis=1)
    wide = []
    for (c, n, y), g in merged.groupby(["å…¬å¸ä»£ç¢¼","å…¬å¸åç¨±","å¹´åº¦"]):
        row = {"å…¬å¸ä»£ç¢¼": c, "å…¬å¸åç¨±": n, "å¹´åº¦": int(y)}
        for _, r in g.iterrows():
            row[r["path"]] = r["æ•¸å€¼"]
        wide.append(row)
    JSON_PATH.write_text(json.dumps(wide, ensure_ascii=False, indent=2), encoding="utf-8")
    print(f"ğŸ“„ è¼¸å‡º CSVï¼š{CSV_PATH.resolve()}")
    print(f"ğŸ“„ è¼¸å‡º JSONï¼š{JSON_PATH.resolve()}")

if __name__ == "__main__":
    main()
